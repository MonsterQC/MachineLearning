{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phân loại hoa với thuật toán K-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import math\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate distance two points\n",
    "def calculate_distance(p1, p2):\n",
    "    dimension = len(p1)\n",
    "    distance = 0\n",
    "    \n",
    "    for i in range(dimension):\n",
    "        distance += (p1[i] - p2[i])*(p1[i] - p2[i])\n",
    "        \n",
    "    return math.sqrt(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_neighbors(X_train, y_train, x_test, k):\n",
    "    distances = []\n",
    "    neighbors = []\n",
    "    \n",
    "    # calculate distance from the point to everything in training X\n",
    "    for i in range(len(X_train)):\n",
    "        distance = calculate_distance(x_test, X_train[i])\n",
    "        distances.append(distance) # C1:\n",
    "        \n",
    "    # position of k smallest distance \n",
    "    index = []\n",
    "    # get k closet points\n",
    "    while len(neighbors) < k:\n",
    "        i = 0\n",
    "        min_distance = 99999\n",
    "        min_idx = 0\n",
    "        while i < len(distances):\n",
    "            # skip the nearest points that have been counted\n",
    "            if i in index:\n",
    "                i += 1\n",
    "                continue\n",
    "                \n",
    "            # update smallest distance and index\n",
    "            if distances[i] <= min_distance:\n",
    "                min_distance = distances[i]\n",
    "                min_idx = i               \n",
    "            i += 1\n",
    "            \n",
    "        # add min index so we skip it in the next iteration    \n",
    "        index.append(min_idx)\n",
    "        neighbors.append(y_train[min_idx])\n",
    "                           \n",
    "# C2: use operator for sort tuple\n",
    "#         distances.append((distance, y_train[i]))\n",
    "        \n",
    "#     distances.sort(key=operator.itemgetter(0))    \n",
    "#     for i in range(k):\n",
    "#         neighbors.append(distances[i][1])\n",
    "        \n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the most popular k labels\n",
    "def highest_votes(labels):\n",
    "    labels_count = [0,0,0]\n",
    "    for label in labels:\n",
    "        labels_count[label] += 1\n",
    "    max_count = max(labels_count)\n",
    "    return labels_count.index(max_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_train, y_train, x_test, k):\n",
    "    neighbors_labels = get_k_neighbors(X_train, y_train, x_test, k)\n",
    "    return highest_votes(neighbors_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(predicts, labels):\n",
    "    total = len(predicts)\n",
    "    correct_count = 0\n",
    "    for i in range(total):\n",
    "        if predicts[i] == labels[i]:\n",
    "            correct_count += 1\n",
    "    \n",
    "    accuracy = correct_count/total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.96\n"
     ]
    }
   ],
   "source": [
    "# phân loại hoa, load datasets\n",
    "iris = datasets.load_iris()\n",
    "iris_X = iris.data # features\n",
    "iris_y = iris.target # label\n",
    "\n",
    "# random index\n",
    "randIndex = np.arange(iris_X.shape[0])\n",
    "np.random.shuffle(randIndex)\n",
    "\n",
    "# random datasets\n",
    "iris_X = iris_X[randIndex]\n",
    "iris_y = iris_y[randIndex]\n",
    "\n",
    "# Split data to train, test\n",
    "X_train = iris_X[:100, :]\n",
    "X_test = iris_X[100:, :]\n",
    "\n",
    "y_train = iris_y[:100]\n",
    "y_test = iris_y[100:]\n",
    "\n",
    "k = 5\n",
    "y_predict = []\n",
    "for x_test in X_test:\n",
    "    label = predict(X_train, y_train, x_test, k)\n",
    "    y_predict.append(label)\n",
    "    \n",
    "accuracy_score = accuracy_score(y_predict, y_test)\n",
    "print(accuracy_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
